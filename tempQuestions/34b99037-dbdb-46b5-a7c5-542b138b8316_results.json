{
  "questions": [
    {
      "text": "Чи можна вважати, що використання бібліотеки TensorFlow для створення моделі ChatGPT викликає виникнення причинно-наслідкового зв'язку між навчанням моделі та її продуктивністю?",
      "options": [
        "Так, оскільки бібліотека TensorFlow забезпечує попередньо навчені моделі для ChatGPT, що підвищує їхню продуктивність.",
        "Ні, оскільки бібліотека TensorFlow лише допомагає навчати моделі, а сама процес навчання залежить від даних та конфігурації моделі.",
        "Так, оскільки використання бібліотеки TensorFlow дозволяє користувачам налаштувати та адаптувати моделі до конкретних потреб, що підвищує їхню ефективність.",
        "Ні, оскільки бібліотека TensorFlow не впливає на процес навчання моделі, який залежить від даних та конфігурації моделі."
      ],
      "correctIndex": 1,
      "explanation": "Правильна відповідь залежить від розуміння причинно-наслідкових зв'язків між навчанням моделі та її продуктивністю. Бібліотека TensorFlow лише допомагає навчати моделі, але не впливає на процес навчання, який залежить від даних та конфігурації моделі. (Посилання на текст: \"Це бібліотека з відкритим кодом для машинного навчання, що включає реалізації ChatGPT. Ці бібліотеки та платформи пропонують інструменти та функції для полегшення навчання та використання ChatGPT...\")",
      "type": "singleChoice"
    },
    {
      "text": "Чим відрізняється використання моделі для створення тексту від використання моделі для створення чат-бота?",
      "options": [
        "Модель для створення тексту використовується для створення статичних текстів, тоді як модель для створення чат-бота використовується для створення інтерактивних діалогів.",
        "Модель для створення тексту використовується для створення коду, тоді як модель для створення чат-бота використовується для створення інтерактивних діалогів.",
        "Модель для створення тексту використовується для створення інтерактивних діалогів, тоді як модель для створення чат-бота використовується для створення статичних текстів.",
        "Модель для створення тексту використовується для створення графічних інтерфейсів, тоді як модель для створення чат-бота використовується для створення інтерактивних діалогів."
      ],
      "correctIndex": 0,
      "explanation": "Порівняння понять використання моделі для створення тексту та використання моделі для створення чат-бота. Правильна відповідь вказує на різницю між статичним текстом та інтерактивним діалогом.",
      "type": "singleChoice"
    },
    {
      "text": "Що відбувається після інтеграції ChatGPT до програми за допомогою бібліотеки, наприклад Hugging Face Transformers, порівняно з іншими способами інтеграції, такі як використання API або створення власної моделі, що називається DeepPa vlov, яке використовує спільно зі ChatGPT для отримання більш природних діалогових відповідей, створюючи природний досвід спілкування для користувачів? ",
      "options": [
        "ChatGPT використовується лише для отримання попередньо навченої моделі.",
        "Бібліотека дозволяє створювати власні моделі, навчаючи їх великим наборами даних.",
        "Інтеграція здійснюється шляхом використання API OpenAI, який надає велику гнучкість з погляду конфігурації моделі та параметрів введення/виводу.",
        "Програма створює власну модель, яка використовує дані користувача для отримання більш точних відповідей.",
        "Бібліотека Hugging Face Transformers використовує спільно зі ChatGPT для створення більш природних діалогових відповідей, створюючи схожий на людський досвід спілкування для користувачів."
      ],
      "correctIndex": 3,
      "explanation": "Після інтеграції ChatGPT до програми за допомогою бібліотеки, наприклад Hugging Face Transformers, вона може створювати власні моделі, які використовують дані користувача для отримання більш точних відповідей. Ця інтеграція дозволяє програмі створювати більш природні діалогові відповіді, створюючи схожий на людський досвід спілкування для користувачів, як вказано в прикладі DeepPa vlov, яке використовує спільно зі ChatGPT для отримання більш природних діалогових відповідей.",
      "type": "singleChoice"
    },
    {
      "text": "Як використовує бібліотека Axios потенціал API OpenAI для отримання відповідей?",
      "options": [
        "Бібліотека Axios використовує API OpenAI для отримання відповідей і відображає їх у веб-сторінці.",
        "Бібліотека Axios надсилає запит до API OpenAI, але не отримує ніяких відповідей.",
        "Бібліотека Axios використовує інформацію, що повертається API, для відображення відповіді, згенерованої чат-ботом.",
        "Бібліотека Axios не використовує API OpenAI для отримання жодної інформації."
      ],
      "correctIndex": 2,
      "explanation": "За змістом тексту бібліотека Axios використовує інформацію, що повертається API OpenAI, для відображення відповіді, згенерованої чат-ботом. Див. рядки 29-31: 'Ми надаємо параметри запиту у вигляді об'єкта JSON і використовуємо інформацію, що повертається API, для відображення відповіді, згенерованої чат-ботом.'",
      "type": "singleChoice"
    },
    {
      "text": "Які дані передаються в API для налаштування відповіді чат-бота відповідно до потреб користувача?",
      "options": [
        "тільки значення параметрів model та max_tokens",
        "значення параметрів model, max_tokens, temperature, top_p та n",
        "значення параметрів model та temperature",
        "ніякі дані не передаються"
      ],
      "correctIndex": 2,
      "explanation": "Відповідь: значення параметрів model, max_tokens, temperature, top_p та n передаються в API для налаштування відповіді чат-бота відповідно до потреб користувача. (Посилання на текст: \"Значення параметрів model, max_tokens, temperature, top_p та n передаються в API для налаштування відповіді чат-бота відповідно до потреб користувача.\")",
      "type": "singleChoice"
    },
    {
      "text": "Яким чином використання параметрів «model» та «prompt» у API OpenAI впливає на створення відповіді?",
      "options": [
        "Використання параметрів «model» та «prompt» не впливає на створення відповіді.",
        "Використання параметрів «model» та «prompt» дозволяє створювати більш передбачувані відповіді.",
        "Використання параметрів «model» та «prompt» дозволяє створювати більш творчі відповіді.",
        "Використання параметрів «model» та «prompt» дозволяє створювати відповіді з більшою кількістю токенів."
      ],
      "correctIndex": 2,
      "explanation": "За текстом, використання параметрів «model» та «prompt» дозволяє створювати більш творчі відповіді, оскільки вони керують вибором моделі та змістом запитання. Прикладом цього є використання моделі «text-davinci-003» та питання, що вказується у полі «prompt». Це дозволяє створювати більш індивідуальні та відповідні запитання, ніж інші параметри.",
      "type": "singleChoice"
    },
    {
      "text": "Як саме модель GPT-3 використовується у відповідях на запит у випадку API OpenAI?",
      "options": [
        "Модель GPT-3 використовується для генерації припущень на основі попередніх запитів користувача.",
        "Модель GPT-3 використовується для обробки запитів користувача та надання відповідей у форматі JSON.",
        "Модель GPT-3 використовується для створення нових запитів на основі раніше згенерованих припущень.",
        "Модель GPT-3 використовується тільки для обробки запитів користувача та надання відповідей у вигляді тексту."
      ],
      "correctIndex": 1,
      "explanation": "У випадку API OpenAI об'єкт відповіді містить припущення, згенеровані моделлю GPT-3 у відповідь на запит. Ці припущення зберігаються у тілі відповіді у вигляді об'єкта JSON з атрибутом вибору, який містить список згенерованих припущень. Тому правильна відповідь - 'Модель GPT-3 використовується для обробки запитів користувача та надання відповідей у форматі JSON'.",
      "type": "singleChoice"
    },
    {
      "text": "Як саме використання async/await в коді програми для виклику API забезпечує простоту та ефективність?",
      "options": [
        "Дозволяє виконувати декілька завдань одночасно",
        "Пов'язує кілька функцій разом у єдиний блок",
        "Очікує завершення запиту до подальшого виконання",
        "Зменшує кількість помилок в програмі"
      ],
      "correctIndex": 2,
      "explanation": "За допомогою async/await код програми очікує завершення запиту до подальшого виконання, забезпечуючи простоту та ефективність. (Посилання на текст: \"Відповідь від дзвінка зберігається в змінній response з використанням await, що забезпечує очікування завершення запиту, перш ніж продовжити виконання.\")",
      "type": "singleChoice"
    },
    {
      "text": "Як можна порівняти бібліотеки для ChatGPT?",
      "options": [
        "Деякі бібліотеки мають більшу кількість попередньо навчених моделей.",
        "Бібліотеки можуть відрізнятися за часом виконання.",
        "Найпопулярніші бібліотеки мають більше спільних бібліотек.",
        "Бібліотеки можуть відрізнятися за кількістю параметрів налаштування."
      ],
      "correctIndexes": [
        0,
        3
      ],
      "explanation": "Бібліотеки для ChatGPT можуть відрізнятися за кількістю попередньо навчених моделей, часом виконання та кількістю параметрів налаштування, тому варіанти 1 і 4 є правильними.",
      "type": "multipleChoice"
    },
    {
      "text": "Як можна інтегрувати ChatGPT до програми?",
      "options": [
        "Використовуючи бібліотеки, такі як Hugging Face Transformers",
        "Створюючи власну модель ChatGPT, навчаючи її великому набору даних",
        "Використовуючи API OpenAI для отримання доступу до попередньо навченої моделі ChatGPT",
        "Використовуючи TensorFlow.js для завантажування та запуску моделі ChatGPT у веб-браузері"
      ],
      "correctIndexes": [
        2
      ],
      "explanation": "Правильним варіантом є використання API OpenAI, оскільки воно дозволяє отримати доступ до попередньо навченої моделі ChatGPT. Інші варіанти також вірні, але вони не є єдиними можливими варіантами для інтеграції ChatGPT.",
      "type": "multipleChoice"
    },
    {
      "text": "Що відрізняє модель text-davinci-003 від інших моделей OpenAI?",
      "options": [
        "Модель text-davinci-003 має більшу кількість параметрів ніж інші моделі OpenAI.",
        "Модель text-davinci-003 використовує архітектуру трансформера на основі GPT-3 із 175 мільярдами параметрів.",
        "Модель text-davinci-003 не використовує архітектуру трансформера, натомість вона використовує нейронну мережу.",
        "Модель text-davinci-003 не має жодних особливостей, що відрізняють її від інших моделей OpenAI."
      ],
      "correctIndexes": [
        1
      ],
      "explanation": "Модель text-davinci-003 відрізняється від інших моделей OpenAI своїм застосуванням архітектури трансформера на основі GPT-3 із 175 мільярдами параметрів, що дозволяє їй генерувати дуже переконливий і зв'язний текст із рівнем точності та складності, що набагато перевершує попередні моделі.",
      "type": "multipleChoice"
    },
    {
      "text": "Що відрізняє функцію reset() від інших функцій у цьому коді?",
      "options": [
        "Функція reset() викликається при натисканні кнопки 'Erase', тоді як інші функції викликаються при інших діях.",
        "Функція reset() скидає вміст поля введення та блоку відповіді чат-бота, тоді як інші функції не виконують цього.",
        "Функція reset() встановлює значення параметрів model, max_tokens, temperature, top_p та n, тоді як інші функції не роблять цього.",
        "Функція reset() запускає API OpenAI, тоді як інші функції не роблять цього."
      ],
      "correctIndexes": [
        1,
        3
      ],
      "explanation": "Функція reset() відрізняється від інших функцій тим, що вона скидає вміст поля введення та блоку відповіді чат-бота, а також встановлює значення параметрів, необхідних для виклику API OpenAI. Ці дії здійснюються саме при натисканні кнопки 'Erase'.",
      "type": "multipleChoice"
    },
    {
      "text": "Що змінює використання async та await в функції generateResponse()?",
      "options": [
        "Усуває необхідність використання callback-функцій",
        "Зменшує можливість виникнення помилок",
        "Дозволяє очікувати завершення запиту до подальшого виконання",
        "Зменшує швидкість виконання програми"
      ],
      "correctIndexes": [
        2
      ],
      "explanation": "За допомогою async та await в функції generateResponse(), розробники можуть очікувати завершення поточного запиту до подальшого виконання, що забезпечує простий і ефективний спосіб обробки запитів до API.",
      "type": "multipleChoice"
    }
  ],
  "metadata": {
    "generatedAt": "2025-11-17T16:44:14.578Z",
    "totalQuestions": 13,
    "difficulty": "medium",
    "keywords": [
      "відповідь",
      "модель",
      "чат",
      "бібліотека",
      "користувач",
      "бот",
      "природний мова",
      "використання",
      "створення",
      "параметр"
    ],
    "singleChoice": 8,
    "multipleChoice": 5,
    "trueFalse": 0,
    "shortAnswer": 0
  }
}