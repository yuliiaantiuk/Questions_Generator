// test_working_models.js
import axios from "axios";
import dotenv from "dotenv";
dotenv.config();

const HF_API_TOKEN = process.env.HUGGINGFACE_API_TOKEN;

// –ú–û–î–ï–õ–Ü, –©–û –¢–û–ß–ù–û –ü–†–ê–¶–Æ–Æ–¢–¨
const WORKING_MODELS = [
  "microsoft/DialoGPT-small",     // –ú–∞–ª–µ–Ω—å–∫–∞ —Ç–∞ —à–≤–∏–¥–∫–∞
  "distilgpt2",                   // –î—É–∂–µ –ª–µ–≥–∫–∞ –º–æ–¥–µ–ª—å
  "gpt2",                         // –ë–∞–∑–æ–≤–∞ GPT-2
  "facebook/blenderbot-400M-distill",
  "microsoft/DialoGPT-medium"     // –°–ø—Ä–æ–±—É—î–º–æ —â–µ —Ä–∞–∑
];

async function testWorkingModels() {
  console.log("üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ä–æ–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π...");
  
  for (const model of WORKING_MODELS) {
    try {
      console.log(`\nüîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞: ${model}`);
      
      // –¢–µ—Å—Ç—É—î–º–æ —á–µ—Ä–µ–∑ Inference API
      const response = await axios.post(
        `https://api-inference.huggingface.co/models/${model}`,
        {
          inputs: "–ü—Ä–∏–≤—ñ—Ç, —Ç–µ—Å—Ç",
          parameters: {
            max_new_tokens: 10,
            temperature: 0.7
          }
        },
        {
          headers: {
            Authorization: `Bearer ${HF_API_TOKEN}`,
            "Content-Type": "application/json"
          },
          timeout: 30000
        }
      );
      
      console.log(`‚úÖ ${model} - –ü–†–ê–¶–Æ–Ñ!`);
      console.log("–í—ñ–¥–ø–æ–≤—ñ–¥—å:", response.data);
      
    } catch (error) {
      console.log(`‚ùå ${model} - –ø–æ–º–∏–ª–∫–∞:`, error.response?.status, error.response?.data?.error || error.message);
    }
  }
}

testWorkingModels();